{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 400 - gradient et backward\n",
        "\n",
        "On peut avoir un r\u00e9seau de neurones comme un gros sandwitch avec de multiples couches de neurones dans lequel on a envie d'ins\u00e9rer sa propre couche mais pour cela il faut interf\u00e9rer avec le gradient. J'ai repris le tutoriel [pytorch: defining new autograd functions](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html). L'exemple suivant [Extending Torch](https://pytorch.org/docs/master/notes/extending.html). J'aimais bien l'API de la version 0.4 mais je ne la trouve plus sur internet. Elle laissait sans doute un peu trop de libert\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch 1.0.1\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "print(\"torch\", torch.__version__)\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "DATA_DIR = 'data/'\n",
        "USE_CUDA = False  # switch to True if you have GPU\n",
        "N_EPOCHS = 2 # 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Couche personnalis\u00e9e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'exemple suivant illustre comment d\u00e9finir une couche interm\u00e9diaire qui ob\u00e9it \u00e0 ses propres r\u00e8gles. Elle doit impl\u00e9menter les deux m\u00e9thodes ``forward`` qui calcule la pr\u00e9diction pour la couche suivante et ``backward`` pour le calcul du gradient pour la couche pr\u00e9c\u00e9dente. Il reste la variable ``ctx`` qui permet de stocker des informations qui persistent jusqu'au calcul du gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyReLU(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## exemple avec MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C'est \u00e0 ce moment que je choisis pour bifurque sur un autre tutoriel [pytorch et MNIST](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) qui commence sur un r\u00e9seau de neurones pour *MNIST*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Le gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On choisit une entr\u00e9e al\u00e9atoire mais aux m\u00eames dimensions qu'une image et on calcule la sortie du r\u00e9seau de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.1206, -0.0651,  0.0964, -0.0375, -0.0080, -0.1063,  0.0421, -0.0432,\n",
            "         -0.0357,  0.0283]], grad_fn=<AddmmBackward>)\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour calculer le gradient, il faut choisir une erreur... On prend le [MSELoss](https://pytorch.org/docs/stable/nn.html?highlight=mseloss#torch.nn.MSELoss) m\u00eame si \u00e7a n'a rien \u00e0 voir avec le probl\u00e8me initial mais on s'en fout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On choisit une entr\u00e9e al\u00e9atoire..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = torch.randn(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On calcule une sortie et on redimensionne la cible de sorte qu'elle est la m\u00eame dimension que la cible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.1206, -0.0651,  0.0964, -0.0375, -0.0080, -0.1063,  0.0421, -0.0432,\n",
              "          -0.0357,  0.0283]], grad_fn=<AddmmBackward>),\n",
              " tensor([[ 0.3268,  0.6423,  0.4603, -1.7247, -0.6567,  1.0883, -0.8122, -0.6066,\n",
              "           0.3827,  0.2351]]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = net(input)\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "output, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Maintenantn on calcule l'erreur de pr\u00e9diction..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6635, grad_fn=<MseLossBackward>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = criterion(output, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Et on calcule enfin le gradient :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je m'attendais \u00e0 trouver le gradient sur la forme d'un beau vecteur mais comme c'est un r\u00e9seau de neurones, le gradient est stock\u00e9 dans chacune des couches sous la forme d'un gradient et encore en deux morceaux..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0026,  0.0060,  0.0018, -0.0010,  0.0144, -0.0085])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.conv1.bias.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 7.7495e-04,  2.0509e-02, -1.5444e-03,  3.2924e-03,  2.8570e-03],\n",
              "          [ 4.3554e-03, -3.8494e-03, -3.6928e-03, -9.9628e-03, -1.4081e-02],\n",
              "          [ 1.6582e-02, -3.6654e-03,  7.2560e-03,  4.3759e-03, -9.0065e-03],\n",
              "          [-4.9111e-03,  3.0753e-03,  1.0345e-02, -2.0349e-02, -5.3538e-03],\n",
              "          [-2.5743e-02, -2.0375e-03, -8.9529e-04,  1.0883e-02, -3.3448e-03]]],\n",
              "\n",
              "\n",
              "        [[[-1.0780e-02,  3.5261e-04,  4.1009e-03,  5.8511e-04,  9.1050e-03],\n",
              "          [ 7.3300e-03,  9.2036e-04,  6.7923e-03,  5.2322e-03,  3.4935e-03],\n",
              "          [ 6.3614e-03, -9.7264e-04, -1.3278e-03,  1.3456e-02, -1.5942e-02],\n",
              "          [-8.9549e-03,  1.0247e-02,  5.9081e-03,  5.0274e-03, -3.4880e-03],\n",
              "          [-1.1709e-02,  8.6279e-03, -5.1750e-03, -7.6851e-03,  1.5142e-02]]],\n",
              "\n",
              "\n",
              "        [[[-9.6119e-03,  1.9943e-02,  1.0360e-02, -1.0992e-02, -1.4673e-03],\n",
              "          [ 5.6452e-03, -1.0945e-02, -4.3214e-03, -1.3912e-03,  6.0289e-03],\n",
              "          [-6.1422e-03, -7.0736e-03,  1.7746e-03,  1.0032e-02,  1.3865e-02],\n",
              "          [-1.3802e-02, -8.8467e-03, -8.1344e-03, -1.5387e-02, -5.9382e-04],\n",
              "          [ 7.1169e-04,  5.0466e-03, -2.2117e-02, -5.4312e-03, -1.4623e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.2676e-02, -1.2479e-02,  6.3768e-04,  6.2096e-03,  8.7049e-03],\n",
              "          [ 4.9450e-03,  1.3229e-02, -1.1343e-02,  3.8833e-03,  5.0434e-05],\n",
              "          [-1.6178e-02, -8.8155e-03,  1.3615e-02, -7.5300e-03,  1.1809e-02],\n",
              "          [ 4.9359e-03,  7.1597e-03, -4.1048e-03, -4.0198e-03, -3.1937e-03],\n",
              "          [-3.2786e-03, -1.5875e-03,  2.5354e-02,  1.4715e-03,  1.7612e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 6.9194e-03, -2.2359e-02, -6.8012e-03, -1.4003e-02,  5.8248e-03],\n",
              "          [-1.1146e-02,  1.9397e-02,  1.2946e-03,  7.6574e-03, -2.4925e-03],\n",
              "          [ 1.5561e-02,  1.4058e-02, -1.4492e-02, -1.9895e-03, -2.4039e-02],\n",
              "          [ 1.4974e-03, -6.5535e-03,  1.1343e-02,  7.7036e-03,  1.0657e-02],\n",
              "          [-1.4202e-02,  1.5361e-03,  9.5525e-03, -2.6720e-03, -4.5329e-03]]],\n",
              "\n",
              "\n",
              "        [[[-1.0270e-03, -4.5524e-03, -7.4217e-03,  9.0858e-03,  8.9269e-03],\n",
              "          [-7.7750e-03,  4.2227e-03, -5.7028e-03, -9.2815e-03, -2.4314e-03],\n",
              "          [-2.7493e-03, -4.0938e-03, -1.3046e-02,  7.2547e-03, -5.4153e-03],\n",
              "          [ 1.0876e-02,  5.5592e-03, -4.5047e-03,  1.1220e-02, -3.5750e-04],\n",
              "          [ 5.2183e-04, -1.7462e-02, -1.4374e-04, -2.2379e-03, -1.8009e-02]]]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net.conv1.weight.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On change de couche\n",
        "\n",
        "Non, il n'est pas trois heures du matin et personne ne pleure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net0(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net0(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net0, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = MyReLU(self.fc1(x))\n",
        "        x = MyReLU(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net0 = Net0()\n",
        "print(net0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evidemment, \u00e7a ne marche jamais du premier coup. On a beaucoup sous-estim\u00e9 le temps de pr\u00e9paration des cours avec l'informatique. Il est seulement 9h du soir, l'humilit\u00e9 vient seulement apr\u00e8s minuit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'MyReLU' object has no attribute 'dim'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    output = net0(input)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "J'avoue que j'ai tout lu en diagonal pensant que ma science infinie me permettrait de combler mon ignorance. Honn\u00eatement, il est temps de d\u00eener !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## After the bug...\n",
        "\n",
        "J'ai craqu\u00e9, je n'ai pas eu le courage de recoder \u00e0 2h du matin trying to figure out what's going wrong. J'ai m\u00e9lang\u00e9 tout ce que j'ai pu trouv\u00e9 et il est quasiment 2h du matin le lendemain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0657,  0.0375, -0.1286,  0.0171, -0.0146,  0.0795,  0.0423,  0.0091,\n",
              "         -0.0872, -0.1257]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyReLUF(torch.autograd.Function):\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        res = input.clamp(min=0)\n",
        "        return res\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        input = self.input\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input\n",
        "\n",
        "    \n",
        "class MyReLUNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyReLUNN, self).__init__()\n",
        "        self.fct = MyReLUF()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.fct(input)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'in_features={}'.format(self.in_features)\n",
        "        \n",
        "\n",
        "class Net2(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.fct1 = MyReLUNN()\n",
        "        self.fct2 = MyReLUNN()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.fct1(self.fc1(x))\n",
        "        x = self.fct2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "    \n",
        "net2 = Net2()\n",
        "output = net2(input)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0657,  0.0375, -0.1286,  0.0171, -0.0146,  0.0795,  0.0423,  0.0091,\n",
              "          -0.0872, -0.1257]], grad_fn=<AddmmBackward>),\n",
              " tensor([[ 0.3268,  0.6423,  0.4603, -1.7247, -0.6567,  1.0883, -0.8122, -0.6066,\n",
              "           0.3827,  0.2351]]))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "output, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.6705, grad_fn=<MseLossBackward>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = criterion(output, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0138, -0.0025, -0.0035, -0.0046,  0.0023, -0.0033])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net2.conv1.bias.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-1.8600e-03, -8.2138e-03,  1.3108e-02,  6.5663e-03,  9.5023e-04],\n",
              "          [ 5.2586e-03,  1.8312e-02,  3.2803e-03, -1.3340e-03,  8.4217e-03],\n",
              "          [ 6.3147e-03, -1.0942e-02, -1.1943e-05, -3.3186e-03,  1.0118e-02],\n",
              "          [ 1.0208e-02, -6.0151e-03, -8.2038e-03, -2.4967e-03, -6.4575e-03],\n",
              "          [-1.5466e-02, -8.3046e-03,  1.2083e-03, -1.1412e-03, -4.6954e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 8.1948e-03, -2.9225e-03, -8.8196e-03,  7.8538e-03, -1.8145e-02],\n",
              "          [-4.1026e-03, -2.1482e-02,  2.5439e-03, -9.5643e-03, -1.5817e-02],\n",
              "          [ 5.4223e-04, -5.6139e-03,  1.3325e-02,  1.7416e-02, -5.9665e-03],\n",
              "          [ 1.5479e-04,  1.0664e-02,  5.8910e-03,  7.4956e-03, -3.5761e-03],\n",
              "          [-1.0230e-02,  5.2740e-03, -4.1645e-03, -1.2707e-03,  1.0064e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 3.5419e-03,  1.0482e-02, -9.5914e-03, -1.3956e-02,  1.8763e-02],\n",
              "          [ 5.3130e-03,  3.9722e-03, -2.2886e-03, -1.0493e-02, -1.0075e-03],\n",
              "          [ 9.7137e-03,  6.4197e-03,  2.3394e-03, -1.1650e-02,  1.4636e-02],\n",
              "          [-2.3253e-03, -1.0510e-02, -1.1862e-02, -1.1520e-02,  1.9171e-03],\n",
              "          [ 1.9330e-02,  2.3783e-03, -1.1798e-02, -7.4532e-03,  4.9577e-04]]],\n",
              "\n",
              "\n",
              "        [[[ 4.0550e-03, -1.0096e-02, -7.6812e-03,  1.3408e-02, -8.5191e-03],\n",
              "          [-5.0063e-03, -7.6191e-03,  3.2311e-03, -7.0888e-03,  3.0374e-04],\n",
              "          [ 1.8902e-02,  1.1674e-02, -1.7747e-03,  4.5612e-03, -4.0779e-03],\n",
              "          [ 2.1848e-03, -3.7517e-03, -6.6000e-03,  4.7719e-03,  6.0781e-03],\n",
              "          [-1.0793e-02, -3.3472e-03, -7.6906e-03,  9.9933e-03, -2.8825e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 6.5017e-03, -5.2726e-03, -1.3388e-02,  8.1185e-03, -1.4097e-03],\n",
              "          [ 1.0049e-02,  1.2856e-02,  1.5342e-03, -4.2778e-03,  1.4622e-02],\n",
              "          [ 2.8377e-03, -7.2327e-03, -1.0655e-02, -3.6696e-04,  1.8354e-03],\n",
              "          [ 1.5145e-02, -1.4855e-02,  3.5839e-03,  2.8900e-03,  5.0477e-03],\n",
              "          [ 1.3973e-03, -6.6431e-03,  2.5495e-03,  5.3310e-03,  4.6650e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 2.4470e-02, -1.0668e-02, -2.2312e-02, -6.2167e-04,  1.3056e-02],\n",
              "          [-9.6521e-04,  3.9517e-03,  3.0850e-03, -8.2513e-04,  2.2127e-03],\n",
              "          [-2.0772e-02,  1.0924e-02,  1.4181e-02, -1.4543e-02, -6.9280e-03],\n",
              "          [ 1.6835e-02,  9.1971e-03, -9.5436e-03,  6.2556e-03, -5.3680e-03],\n",
              "          [ 5.4010e-03,  9.6061e-05,  1.1978e-02,  6.6822e-03, -2.3094e-03]]]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net2.conv1.weight.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ca converge ?\n",
        "\n",
        "Il ne reste plus qu'\u00e0 voir si cela converge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}